
# 依赖库

* findspark            1.3.0
* pyspark              2.4.4
* httpagentparser      1.9.0

# 目的

针对音乐类服务的用户行为数据，预测哪些用户可能流失、哪些用户会降级服务(从付费到免费)，或者这取消服务。
如果能预测出这些用户，通过打折已激励的方式留住他们，以挽救数百万的营业额。

#  Spark_Predict_user_churn.ipynb 文件说明

**包含主要步骤如下**

1. 清理数据
2. 探索数据
    1. 探索如下特征对用户是否取消服务的影响
        * 用户点赞、踩
        * 添加好友
        * 添加歌曲
        * 听歌频率
        * 设置功能
        * 使用设备
        * 注册时长
        * 升级、降级
        * 访问Home、About、Help次数
        * Error次数
        * 查看滚动广告的次数
    2. 结论
        * 使用Setting多的用户，越不容易取消服务, 说明用户乐于使用产品
        * 使用Ubuntu取消服务偏多、iPad使用人取消服务人相对较少
        * 取消服务的人明显听歌数量也偏少
        * 查看滚动广告越多的，越容易取消服务
        * 越少的降级发生越好
        * 点赞越少的用户，越倾向于取消服务
        * 添加好友和添加歌曲少于20的用户，越可能取消服务
        * 添加好友次数越少的用户，越倾向于取消服务
        
        
3. 特征工程
    * 统计用户访问page页全量行为数据
    * 计算用户注册时长(单位：天)、经常使用设备类型
    * 探索获取用户流失最多的时段(子集)，统计这个时段内，用户访问page也的行为数据
    * 计算子集对应page访问行为相对于总page访问行为占比
    * 标准化数据
    * one-hot
4. 建模
    * 使用GBTClassifier 梯度提升决策树 建模预测
    * stepSize=0.01, 其他参数默认
    * 评估指标 Accuracy、F1-Score


# 总结

## 反思
经过完整的流程：数据清理、数据可视化探索、特征工程、建模、模型评估。
其中最喜欢的是数据可视化和建模部分，可视化可以发现数据特征隐藏的关联关系，
建模则可以利用这些关系完成预测。更重要的是特征工程，特征往往决定了模型能得到的高度。
特征构建、提取需要往往需要团队的协助完成。

## 改进 

### f1 score得分较低原因分析
* 数据样本较少
* 特征提取不够精细
* 未使用Kfold交叉检验
* 未调参
